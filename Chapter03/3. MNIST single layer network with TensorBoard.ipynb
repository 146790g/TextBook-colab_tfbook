{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. MNIST single layer network with TensorBoard.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyYNTPtMEVFS",
        "colab_type": "text"
      },
      "source": [
        "# MNIST Single Layer Network with TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mpClHxXL51l",
        "colab_type": "text"
      },
      "source": [
        "Note: This notebook is desinged to run with Python3 and GPU runtime.\n",
        "\n",
        "![Python 3 and CPU runtime](https://raw.githubusercontent.com/enakai00/colab_tfbook/master/docs/imgs/runtime_gpu.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4qbP7L1QSqR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0097b6b0-3883-4657-8cd1-58666b3ccf5b"
      },
      "source": [
        "%%bash\n",
        "tf_version='2.0.0rc0'\n",
        "if pip freeze | grep -q \"^tensorflow==${tf_version}$\"; then\n",
        "  echo \"tensorflow==${tf_version} is already installed. No actions are required.\"\n",
        "else\n",
        "  echo \"Installing tensorflow==${tf_version}. Don't forget to restart the runtime.\"\n",
        "  pip install tensorflow==${tf_version}\n",
        "fi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow==2.0.0rc0 is already installed. No actions are required.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJO3PPzqsq8d",
        "colab_type": "text"
      },
      "source": [
        "####[MST-01]\n",
        "Import modules and set random seeds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB5UUoAXIVmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame, Series\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, initializers, callbacks\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "np.random.seed(20190228)\n",
        "tf.random.set_seed(20190228)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz2h7_8St1wi",
        "colab_type": "text"
      },
      "source": [
        "####[MST-02]\n",
        "Download the MNIST dataset and store into NumPy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASgzWK5AjWvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape(\n",
        "                  (len(train_images), 784)).astype('float32') / 255\n",
        "test_images = test_images.reshape(\n",
        "                  (len(test_images), 784)).astype('float32') / 255\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdQ0Tp2IvFy8",
        "colab_type": "text"
      },
      "source": [
        "####[MST-03]\n",
        "Define a model with a single hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpL_niBTXggS",
        "colab_type": "code",
        "outputId": "891b5f08-546a-4262-ad6c-e92455a30eec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(1024, activation='relu', input_shape=(28*28,),\n",
        "                       kernel_initializer=initializers.TruncatedNormal(),\n",
        "                       name='hidden'))\n",
        "model.add(layers.Dense(10, activation='softmax', name='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden (Dense)               (None, 1024)              803840    \n",
            "_________________________________________________________________\n",
            "softmax (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 814,090\n",
            "Trainable params: 814,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBltXsSRvZn0",
        "colab_type": "text"
      },
      "source": [
        "####[MST-04]\n",
        "Compile the model using the Adam optimizer, and Cross entroy as a loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BakcuKxdQoSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdIktV-vFDof",
        "colab_type": "text"
      },
      "source": [
        "####[MST-05]\n",
        "Train the model with the callbacks option to store training logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlQCTsKKXkr5",
        "colab_type": "code",
        "outputId": "86f72c0d-dfb0-473b-840e-77abe5ed7e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "log_dir = '/tmp/log'\n",
        "shutil.rmtree(log_dir, ignore_errors=True)\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir=log_dir,\n",
        "                                             histogram_freq=1)\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    batch_size=128, epochs=10,\n",
        "                    callbacks=[tensorboard_callback])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.2311 - acc: 0.9339 - val_loss: 0.1189 - val_acc: 0.9643\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0909 - acc: 0.9734 - val_loss: 0.0828 - val_acc: 0.9743\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0558 - acc: 0.9835 - val_loss: 0.0669 - val_acc: 0.9788\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0390 - acc: 0.9887 - val_loss: 0.0619 - val_acc: 0.9801\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0254 - acc: 0.9925 - val_loss: 0.0589 - val_acc: 0.9821\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0186 - acc: 0.9949 - val_loss: 0.0605 - val_acc: 0.9823\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0146 - acc: 0.9957 - val_loss: 0.0600 - val_acc: 0.9823\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0096 - acc: 0.9977 - val_loss: 0.0658 - val_acc: 0.9796\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0086 - acc: 0.9976 - val_loss: 0.0653 - val_acc: 0.9816\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0718 - val_acc: 0.9800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpSePiAysZHn",
        "colab_type": "text"
      },
      "source": [
        "####[MST-06]\n",
        "Install ngrok to run TensorBoard on Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqHkMyJHYFTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "01711f50-ea5d-46a5-9afd-06296657b55b"
      },
      "source": [
        "!curl -OL https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 12.9M  100 12.9M    0     0  43.5M      0 --:--:-- --:--:-- --:--:-- 43.5M\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCHxA0sKahqD",
        "colab_type": "text"
      },
      "source": [
        "####[MST-07]\n",
        "Start TensorBoard and prepare the connection URL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3oGrHRwWz58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "586e933f-4942-4fd8-d373-c93baaa21240"
      },
      "source": [
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(log_dir)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://9d60b02e.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}