{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. MNIST single layer network with TensorBoard.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyYNTPtMEVFS",
        "colab_type": "text"
      },
      "source": [
        "# MNIST Single Layer Network with TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mpClHxXL51l",
        "colab_type": "text"
      },
      "source": [
        "Note: This notebook is desinged to run with Python3 and GPU runtime.\n",
        "\n",
        "![Python 3 and CPU runtime](https://raw.githubusercontent.com/enakai00/colab_tfbook/master/docs/imgs/runtime_gpu.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEcsPed9AUfE",
        "colab_type": "text"
      },
      "source": [
        "This notebook uses TensorFlow2.x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4qbP7L1QSqR",
        "colab_type": "code",
        "outputId": "ec39de38-6369-42a5-a6a9-14b40357fb77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJO3PPzqsq8d",
        "colab_type": "text"
      },
      "source": [
        "####[MST-01]\n",
        "Import modules and set random seeds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB5UUoAXIVmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame, Series\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, initializers, callbacks\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "np.random.seed(20190228)\n",
        "tf.random.set_seed(20190228)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz2h7_8St1wi",
        "colab_type": "text"
      },
      "source": [
        "####[MST-02]\n",
        "Download the MNIST dataset and store into NumPy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASgzWK5AjWvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape(\n",
        "                  (len(train_images), 784)).astype('float32') / 255\n",
        "test_images = test_images.reshape(\n",
        "                  (len(test_images), 784)).astype('float32') / 255\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdQ0Tp2IvFy8",
        "colab_type": "text"
      },
      "source": [
        "####[MST-03]\n",
        "Define a model with a single hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpL_niBTXggS",
        "colab_type": "code",
        "outputId": "a9603f35-85d1-40e6-ce4f-ab460f54c86e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(1024, activation='relu', input_shape=(28*28,),\n",
        "                       kernel_initializer=initializers.TruncatedNormal(),\n",
        "                       name='hidden'))\n",
        "model.add(layers.Dense(10, activation='softmax', name='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden (Dense)               (None, 1024)              803840    \n",
            "_________________________________________________________________\n",
            "softmax (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 814,090\n",
            "Trainable params: 814,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBltXsSRvZn0",
        "colab_type": "text"
      },
      "source": [
        "####[MST-04]\n",
        "Compile the model using the Adam optimizer, and Cross entroy as a loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BakcuKxdQoSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdIktV-vFDof",
        "colab_type": "text"
      },
      "source": [
        "####[MST-05]\n",
        "Train the model with the callbacks option to store training logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlQCTsKKXkr5",
        "colab_type": "code",
        "outputId": "ac9eb3bb-62ce-4c7c-93bf-dac695c5c22e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "log_dir = '/tmp/log'\n",
        "shutil.rmtree(log_dir, ignore_errors=True)\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir=log_dir,\n",
        "                                             histogram_freq=1)\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    batch_size=128, epochs=10,\n",
        "                    callbacks=[tensorboard_callback])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0827 07:37:00.962392 140001471883136 deprecation.py:323] From /tensorflow-2.0.0b1/python3.6/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "  128/60000 [..............................] - ETA: 4:43 - loss: 2.3443 - acc: 0.1328"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0827 07:37:01.958352 140001471883136 callbacks.py:241] Method (on_train_batch_end) is slow compared to the batch update (0.120098). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2319 - acc: 0.9330 - val_loss: 0.1150 - val_acc: 0.9655\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0901 - acc: 0.9738 - val_loss: 0.0815 - val_acc: 0.9756\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0563 - acc: 0.9833 - val_loss: 0.0712 - val_acc: 0.9774\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0375 - acc: 0.9886 - val_loss: 0.0645 - val_acc: 0.9802\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0273 - acc: 0.9920 - val_loss: 0.0679 - val_acc: 0.9796\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0188 - acc: 0.9948 - val_loss: 0.0608 - val_acc: 0.9806\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0139 - acc: 0.9961 - val_loss: 0.0596 - val_acc: 0.9826\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0114 - acc: 0.9968 - val_loss: 0.0695 - val_acc: 0.9800\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 26us/sample - loss: 0.0086 - acc: 0.9976 - val_loss: 0.0679 - val_acc: 0.9809\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0113 - acc: 0.9966 - val_loss: 0.0675 - val_acc: 0.9819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpSePiAysZHn",
        "colab_type": "text"
      },
      "source": [
        "####[MST-06]\n",
        "Install ngrok to run TensorBoard on Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqHkMyJHYFTb",
        "colab_type": "code",
        "outputId": "fc636387-9a99-44be-cb84-2a38e4a2b08b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!curl -OL https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 12.9M  100 12.9M    0     0  3823k      0  0:00:03  0:00:03 --:--:-- 3825k\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCHxA0sKahqD",
        "colab_type": "text"
      },
      "source": [
        "####[MST-07]\n",
        "Start TensorBoard and prepare the connection URL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3oGrHRwWz58",
        "colab_type": "code",
        "outputId": "d4e0f6d1-d2a4-490a-c6d7-50d0183e28b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(log_dir)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://a8bbf2af.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}